/*
 *  [The "BSD license"]
 *  Copyright (c) 2002-2011, Rodney O'Donnell, Lloyd Allison, Kevin Korb
 *  Copyright (c) 2002-2011, Monash University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions
 *  are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the author may not be used to endorse or promote products
 *       derived from this software without specific prior written permission.*
 *
 *  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 *  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 *  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 *  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 *  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 *  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 *  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

//
// Weka classifier interface for CaMML/CDMS
//

// File: CammlClassifier.java
// Author: {rodo,lhope}@csse.monash.edu.au

package camml.plugin.weka;

import java.util.Vector;
import java.util.Enumeration;
import java.io.*;

import weka.core.*;
import weka.classifiers.*; 

import camml.plugin.weka.Converter;

import cdms.core.*;
import camml.core.models.ModelLearner;
import camml.core.models.bNet.*;
import camml.core.search.SearchPackage;

import weka.filters.supervised.attribute.Discretize;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

/**
 * Class to interface with the java version of Camml.
 *
 * Learn a Bayes Net from data.
 * 
 * @author Luke Hope <lhope@csse.monash.edu.au>
 * @version $Revision: 1.2 $ $Date: 2006/09/13 09:58:44 $
 * $Source: /u/csse/public/bai/bepi/cvs/CAMML/Camml/camml/plugin/weka/CaMMLClassifier.java,v $
 */
public class CaMMLClassifier extends Classifier
{
    /** 
        ModelLearner function used in this classifier.
    */
    protected ModelLearner modelLearner;
    
    /** Model generated by modelLearner */
    protected Value.Model model = null;
    
    /** parameters generated by modelLearner */
    protected Value params = null;
    
    /**
     * Filter to discretize missing values.  This is initialised in buildClassifier. <br>
     * If the instances passed to buildClassifier have a discrete target attribute MDL is used for
     *  optimal binning.  If not a less intelligent method bins each attribute into 10 bins.
     */
    protected Discretize discreteFilter;
    //protected DiscretizeFilter discreteFilter;
    
    /**
     * missingFilter replaces each missing value with the mode likely value for that attribute.
     */
    protected ReplaceMissingValues missingFilter;
    //protected ReplaceMissingValuesFilter missingFilter;
    
    /**
     * A replacement for <code>/dev/null</code>
     *
     * This is to shut off CaMML's outputs when not in debug mode.
     */
    protected class DevNull extends OutputStream
    {
        /**
         * Does nothing with the specified byte.
         *
         * @param      b the <code>byte</code> to ignore.
         * @exception  IOException  if an I/O error occurs.
         */
        public void write(int b) throws IOException
        { }
    }

    /**********************************
     * WEKA OPTION HANDLING VARIABLES *
     **********************************/
    
    protected boolean verbose = false;

    /**
       cpdLearner is the ModelLearner responsible for coding the
       conditional probability distributions in network nodes.  It
       defaults to a table encoding.
    */
    protected ModelLearner cpdLearner = camml.core.models.cpt.CPTLearner.mmlAdaptiveCPTLearner;

    /** A string representing the encoding options. Defaults to "cpt". */
    protected String encoding = "cpt";

    protected boolean weightedAverage = false;

    /** The default arc probability (0.5) */
    public final double ARC_DEFAULT = 0.5;

    protected double arcProbability = ARC_DEFAULT;

    protected double searchMultiplier = 1.0;

    /** The default temperature (1.0) */
    public final double TEMP_DEFAULT = 1.8;

    protected double temperature = TEMP_DEFAULT;

    protected String priors = "";

    /**********************************/

    /** ModelLearnerClassifier constructor simply sets modelLearner variable */
    public CaMMLClassifier() {
        super();
    }

    /**
     * Initialize filters based on instances provided.  <br>
     * NOTE: This function does NOT actually do the filtering
     */
    public void initializeFilters( Instances instances ) throws Exception
    {
        // Initialise the discrete filter.
        discreteFilter = new Discretize();
        //discreteFilter = new DiscretizeFilter();
        if ( (instances.classIndex() == -1) || (!instances.classAttribute().isNominal()) ) {
            //discreteFilter.setUseMDL(false);
        }
        else {        
            discreteFilter.setUseBetterEncoding(true);
        }    
        discreteFilter.setInputFormat(instances);
        
        // We need this to get the correct output input format into missingFilter
        Instances temp = weka.filters.Filter.useFilter( new Instances(instances), discreteFilter );
        
        
        // Initialise and run the missing value filter.
        missingFilter = new ReplaceMissingValues();
        //missingFilter = new ReplaceMissingValuesFilter();
        missingFilter.setInputFormat( temp );
    }
    
    /** return a copy of instances with discrete and missingValue filters applied to it. */
    public Instances filterInstances( Instances instances ) throws Exception
    {
        Instances instancesCopy = new Instances( instances );
        instancesCopy =  weka.filters.Filter.useFilter( instancesCopy, discreteFilter );
        instancesCopy = weka.filters.Filter.useFilter( instancesCopy, missingFilter );
        return instancesCopy;
    }

    /** 
     * Generates the ModelLearner using the options.  encoding and
     * weightedAverage are set directly, and other options are set via
     * BNetSearch.setOption(java.lang.String option, Value v)
     */
    protected ModelLearner generateLearner() {
        BNetLearner learner =
            new BNetLearner( SearchPackage.mlCPTLearner, cpdLearner, weightedAverage, false);

        // rest of configuration here.    
        Vector options = new Vector(); // string
        Vector values = new Vector(); // Value

        // switch on Netica.
        options.add("useNetica");
        values.add(new Value.Discrete(0));
    
        // Note, arcProbability must come BEFORE priors, because priors locks it in.
        if(arcProbability != ARC_DEFAULT) {
            options.add("arcProb");
            values.add(new Value.Continuous(arcProbability));
        }

        if(searchMultiplier != 1.0) {
            options.add("searchFactor");
            values.add(new Value.Continuous(searchMultiplier));
        }

        if(temperature != TEMP_DEFAULT) {
            options.add("temperature");
            values.add(new Value.Continuous(temperature));
        }

        // Note, priors must come AFTER arcProbability, as any further changes will be ignored.
        if(!priors.equals("")) {
            try { 
                File file = new File(priors);
                // Ignoring a very strange case where the text for setting the prior is the same as a filename.
                if(file.canRead()) { // if it's a file

                    BufferedReader in = 
                        new BufferedReader(new InputStreamReader(new FileInputStream(file)));
                    StringBuffer buf = new StringBuffer();
                    String line;
            
                    while((line = in.readLine()) != null) {
                        buf.append(line);
                        buf.append('\n');
                    }

                    values.add(new Value.Str(buf.toString()));
            
                }
                else // if it's set on the command line.
                    { values.add(new Value.Str(priors)); }

                // this is in the try so if there is a failure in the values the whole TomPrior gets ignored.
                options.add("TOMPrior");
            } catch(java.io.IOException e)
                { e.printStackTrace(); }
        }
    
        // convert the option vectors here.
        if(options.size() > 0) { 
            String[] optionArray = new String[options.size()];
            Value[] valueArray = new Value[values.size()];
            learner.setOptions((String[])options.toArray(optionArray), (Value[])values.toArray(valueArray));
        }
    
        return learner;
    }    
    
    /**
     * Use the modelLearner to build the classifier.
     *
     * @param instances set of instances serving as training data 
     * @exception Exception if the classifier has not been generated 
     * successfully
     */
    public synchronized void buildClassifier(Instances instances) throws Exception {

        PrintStream stdOut = System.out;
        if(!verbose) 
            { System.setOut(new PrintStream(new DevNull(), true)); }

        // generate learner based on the options
        modelLearner = generateLearner();

        // Set up data for Camml
        initializeFilters( instances );
        Instances instancesCopy = filterInstances( instances  );
        Value.Vector data = Converter.instancesToVector( instancesCopy );
        
        
        
        Value.Structured msy = modelLearner.parameterize( Value.TRIV, data, data );    
        this.model = (Value.Model)msy.cmpnt(0);
        
        // Netica does significantly faster/more accurate inference than my stochastic algorithm.
        //  so if the model returnes is stochastic, convert it to Netica's exact method.
        if ( this.model instanceof BNetStochastic ) {
            Type.Structured dataType = (Type.Structured)((Type.Model)this.model.t).dataSpace;
            this.model = new camml.plugin.netica.BNetNetica( dataType );
        }
        
        this.params = msy.cmpnt(2);

        // restore standard out.
        System.setOut(stdOut);
    }
    
    
    
    /**
     * Calculates the class membership probabilities for the given test 
     * instance.
     *
     * @param instance the instance to be classified
     * @return predicted class probability distribution
     * @exception Exception if there is a problem generating the prediction
     */
    public double [] distributionForInstance(Instance instance) 
        throws Exception { 
        
        // Apply discreteFilter to instance.
        // NOTE: Missing value filter is NOT required as Bayes Networks can cope with missing vals.
        discreteFilter.input( instance );
        Instance filteredInstance = discreteFilter.output( );
        
        
        
        int classVariable = filteredInstance.classAttribute().index();
        
        Value.Structured instanceStruct = Converter.instanceToStruct( filteredInstance );
        Type.Structured sType = ((Type.Structured)instanceStruct.t);
        Type[] type = sType.cmpnts;
        String[] nameArray = sType.labels;
        Type.Discrete classType = (Type.Discrete)type[classVariable];
        int arity = (int)classType.UPB - (int)classType.LWB + 1;    
        
        Value[] inputArray = new Value[instanceStruct.length()];
        Value[][] outputArray = new Value[arity][instanceStruct.length()];
        
        
        // Loop through each variable in order.
        for ( int i = 0; i < inputArray.length; i++ ) {
            
            // Input of target variable is missing, output is set to each possible value to create
            // a multistate distribution.
            if ( i == classVariable ) {
                inputArray[i] = new Value.Discrete( (Type.Discrete)type[i], 
                                                    Value.S_UNOBSERVED, 0 );
                for ( int j = 0; j < arity; j++ ) {
                    outputArray[j][i] = new Value.Discrete( (Type.Discrete)type[i],
                                                            Value.S_PROPER, 
                                                            (int)classType.LWB + j );
                }
            }
            // Missing values are missing on both input and output.
            else if ( filteredInstance.isMissing(i) ) {
                inputArray[i] = new Value.Discrete( (Type.Discrete)type[i], Value.S_UNOBSERVED, 0 );
                for ( int j = 0; j < arity; j++ ) {
                    outputArray[j][i] = inputArray[i];
                }
                
            }
            // Regular values are present in both input and output.
            else {
                inputArray[i] = instanceStruct.cmpnt(i);
                for ( int j = 0; j < arity; j++ ) {
                    outputArray[j][i] = instanceStruct.cmpnt(i);
                }
            }
        }
        
        Value.Structured input = new Value.DefStructured( inputArray, nameArray );
        Value.Structured[] output = new Value.Structured[arity];
        for ( int i = 0; i < output.length; i++ ) {
            output[i] = new Value.DefStructured( outputArray[i], nameArray );
        }
        
        
        double[] prob = new double[arity];
        for ( int i = 0; i < prob.length; i++ ) {
            prob[i] = Math.exp( model.logP( output[i], params, input ) );
        }
        
        return prob;
        
    }
    
    public String toString()
    {
        if ( model instanceof camml.plugin.netica.BNetNetica ) {
            camml.plugin.netica.BNetNetica bNet = (camml.plugin.netica.BNetNetica)model;        
            return bNet.toString( (Value.Vector)params, "NET_TITLE","COMMENT" );
        }
        else if ( model instanceof BNet ) {
            return ((BNet)model).makeString( (Value.Vector)params );
        }
        else return "(" + model + "," + params + ")";
    }

    /********************************************************
     * The main method to evaluate the model.
     * Calls weka.classifiers.Evaluation.evaluateModel 
     * on CaMMLWrapper.
     *********************************************************/
    public static void main(String [] argv) {
        try {
            System.out.println(Evaluation.evaluateModel(new CaMMLClassifier(), argv));
        } catch (Exception e)
            { e.printStackTrace(); }
    }



    /************************************
     *
     * Option Handling Routines
     *
     ************************************/

    public String globalInfo() {
        return "The Causal MML (CaMML) Bayesian Network classifier."
            + " CaMML generates a Bayesian Network using"
            + " a Metropolis search through the space of causal (Bayesian) models, guided"
            + " by a Minimum Message Length (MML) scoring metric. MML is related to MDL and"
            + " jointly scores the model and the fit of the data to the model.  CaMML does"
            + " does not directly support numeric variables, but discretizes them using"
            + " Weka's MDL discretizer (or optionally, a fixed number of bins)."
            + " It corrently deals with missing values in the training set by removing all"
            + " instances with them, which we regard as a bug."
            + "\n"
            + " See also:\n"
            + "  *  K.B. Korb and A.N. Nicholson 2003. <i>Bayesian Artificial Intelligence</i>."
            + " CRC Press. Esp. 207--217.\n"
            + "  *  C.S. Wallace and K.B. Korb 1999. Learning linear causal models by MML sampling."
            + " In A. Gammerman, <i>Causal Models and Intelligent Data Management</i>"
            + " 89--111 Springer-Verlag\n"
            + " For more references and information, visit the website:\n"
            + "  *  http://www.datamining.monash.edu.au/software/camml\n";
    }

    /**
     * Returns an enumeration describing the available options
     *
     * @return an enumeration of all the available options
     */
    public Enumeration listOptions() {
    
        Vector newVector = new Vector();

        newVector.addElement(new Option("\t" + verboseTipText(),
                                        "V", 0,"-V"));

        newVector.addElement(new Option("\t" + encodingTipText(),
                                        "E", 1, "-E"));

        newVector.addElement(new Option("\t" + weightedAverageTipText(),
                                        "W", 0, "-W"));

        newVector.addElement(new Option("\t" + arcProbabilityTipText(),
                                        "A", 1, "-A"));

        newVector.addElement(new Option("\t" + searchMultiplierTipText(),
                                        "M", 1, "-M"));

        newVector.addElement(new Option("\t" + temperatureTipText(),
                                        "T", 1, "-T"));

        newVector.addElement(new Option("\t" + priorsTipText(),
                                        "P", 1, "-P"));
    
        return newVector.elements();
    }
    
    /**
     * Parses a given list of options.
     *
     -E 
     Specify the node encoding (one or more of cpt,dtree,logit,all). More
     than one means use the best encoding on a node by node basis.
     cpt - encode as a conditional probability table.
     dtree - encode as a decision tree.
     logit - encode as a logistical model.
     all - encode as best of all three.
     Fastest and default is cpt, all gets the best results.
     -W
     Use a weighted average of models to predict instead of the single best one.
     -A
     Set the a priori probability of an arc between any two nodes (defaults to 0.5).
     -M
     Multiply the standard search by the given factor.Less than one is faster, greater than one is slower.
     -T
     Fix_bnt_output the temperature at a set value (defaults to 1.0).
     * @param options the list of options as an array of strings
     * @exception Exception if an option is not supported
     */
    public void setOptions(String[] options) throws Exception {

        setVerbose(Utils.getFlag('V', options));
    
        setEncoding(Utils.getOption('E', options));

        setWeightedAverage(Utils.getFlag('W', options));
    
        try 
            { setArcProbability(Double.parseDouble(Utils.getOption('A', options))); }
        catch(NumberFormatException e) {}

        try 
            { setSearchMultiplier(Double.parseDouble(Utils.getOption('M', options))); }
        catch(NumberFormatException e) {}

        try 
            { setTemperature(Double.parseDouble(Utils.getOption('T', options))); }
        catch(NumberFormatException e) {}

        setPriors(Utils.getOption('P', options));

        Utils.checkForRemainingOptions(options);
    }

    
    
    /**
     * Gets the current settings of the classifier.
     *
     * @return an array of strings suitable for passing to setOptions
     */
    public String [] getOptions() {
    
        String [] options = new String [7];
        int current = 0;
    
        if(verbose)
            { options[current++] = "-V"; }

        options[current++] = "-E " + encoding;

        if(weightedAverage)
            { options[current++] = "-W"; }

        if(arcProbability != ARC_DEFAULT)
            { options[current++] = "-A " + arcProbability; }

        if(searchMultiplier != 1.0)
            { options[current++] = "-M " + searchMultiplier; }

        if(temperature != TEMP_DEFAULT)
            { options[current++] = "-T " + temperature; }

        // I have a feeling that additional quoting might be needed.
        if(!priors.equals(""))
            { options[current++] = "-P\" " + "\"" + priors; } 

        while (current < options.length) {
            options[current++] = "";
        }
        return options;
    }

    public String verboseTipText() {
        return "Print progress indicators and other information to standard output.";
    }

    public boolean getVerbose() {
        return verbose;
    }

    public void setVerbose(boolean newval) {
        verbose = newval;
    }

    public String encodingTipText() {
        return "Specify the node encoding (one or more of cpt,dtree,logit,all)."
            + " More than one means use the best encoding on a node by node basis.\n"
            + "cpt - encode as a conditional probability table.\n"
            + "dtree - encode as a decision tree.\n"
            + "logit - encode as a logistical model.\n"
            + "all - encode as best of all three.\n"
            + "Fastest and default is cpt, all gets the best results.";
    }

    public void setEncoding(String e) {
        e = e.toLowerCase();

        if(e.contains("all")) {
            encoding = "all";
            cpdLearner = camml.core.models.dual.DualLearner.dualCPTDTreeLogitLearner; 
        }
        else {
            boolean c = e.contains("cpt");
            boolean d = e.contains("dtree");
            boolean l = e.contains("logit");
            if(c) {
                if(d) {
                    if(l) {
                        encoding = "all";
                        cpdLearner = camml.core.models.dual.DualLearner.dualCPTDTreeLogitLearner; 
                    }
                    else {
                        encoding = "cpt,dtree";
                        cpdLearner = camml.core.models.dual.DualLearner.dualCPTDTreeLearner;
                    }
                }
                else if(l) {
                    encoding = "cpt,logit";
                    cpdLearner = camml.core.models.dual.DualLearner.dualCPTLogitLearner; 
                }
                else {
                    encoding = "cpt";
                    cpdLearner = camml.core.models.cpt.CPTLearner.mmlAdaptiveCPTLearner;
                }
            }
            else if(d) {
                if(l) {
                    encoding = "dtree,logit";
                    cpdLearner = camml.core.models.dual.DualLearner.dualDTreeLogitLearner; 
                }
                else {
                    encoding = "dtree";
                    cpdLearner =
                        camml.core.models.dTree.ForcedSplitDTreeLearner.multinomialDTreeLearner;
                }
            }
            else if(l) {
                encoding = "logit";
                cpdLearner = camml.core.models.logit.LogitLearner.logitLearner;
            }
            else {
                encoding = "cpt";
                cpdLearner = camml.core.models.cpt.CPTLearner.mmlAdaptiveCPTLearner;
            }
        }
    }
           
    public String getEncoding() {
        return encoding;
    }

    public String weightedAverageTipText() {
        return "Use a weighted average of models to predict instead of the single best one.";
    }

    public boolean getWeightedAverage() {
        return weightedAverage;
    }

    public void setWeightedAverage(boolean newval) {
        weightedAverage = newval;
    }

    public String arcProbabilityTipText() {
        return "Set the a priori probability of an arc between any two nodes (defaults to " + ARC_DEFAULT + ").";
    }

    public void setArcProbability(double newval) {
        arcProbability = newval;
    }

    public double getArcProbability() {
        return arcProbability;
    }

    public String searchMultiplierTipText() {
        return "Multiply the standard search by the given factor."
            + "Less than one is faster, greater than one is slower.";
    }

    public void setSearchMultiplier(double newval) {
        searchMultiplier = newval;
    }

    public double getSearchMultiplier() {
        return searchMultiplier;
    }

    // todo a better description.
    public String temperatureTipText() {
        return "Set the monte-carlo search temperature (defaults to " + TEMP_DEFAULT + ").";
    }

    public void setTemperature(double newval) {
        temperature = newval;
    }

    public double getTemperature() {
        return temperature;
    }

    // todo a better description.
    public String priorsTipText() {
        return "Set a prior probability over the modelspace using either a filename or"
            + " on the command line. (See camml.plugin.tomCoster.ExpertElicitedTOMCoster for more info.)";
    }
    
    public void setPriors(String newval) {
        priors = newval;
    }

    public String getPriors() {
        return priors;
    }
}


